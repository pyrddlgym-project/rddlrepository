domain Navigation {

    requirements = {
        concurrent,           // this domain permits multiple non-default actions
        continuous,           // this domain uses real-valued parameterized variables
        intermediate-nodes,   // this domain uses intermediate pvariable nodes
        reward-deterministic  // this domain does not use a stochastic reward
    };

    types {
        dim: object;
        zone: object;
    };

    pvariables {
        MIN_ACTION_BOUND(dim): { non-fluent, real, default = -1.0 };
        MAX_ACTION_BOUND(dim): { non-fluent, real, default =  1.0 };

        GOAL(dim): { non-fluent, real, default = 0.0 };

        DECELERATION_ZONE_CENTER(zone, dim) : { non-fluent, real, default = 0.0 };
        DECELERATION_ZONE_DECAY(zone): { non-fluent, real, default = 2.0 };

        MOVE_MEAN(dim) : { non-fluent, real, default = 0.0 };
        MOVE_VARIANCE_MULT(dim) : { non-fluent, real, default = 0.05 };

        distance(zone): { interm-fluent, real, level = 1 };
        deceleration(zone): { interm-fluent, real, level = 2 };

        location(dim): { state-fluent, real, default = 0.0 };

        move(dim): { action-fluent, real, default = 0.0 };
    };

    cpfs {
        distance(?z) = sqrt[ sum_{?l:dim} [ pow[ (DECELERATION_ZONE_CENTER(?z, ?l) - location(?l)), 2 ] ] ];
        deceleration(?z) = 2.0 / (1.0 + exp[-DECELERATION_ZONE_DECAY(?z) * distance(?z) ]) - 1.00;
        location'(?l) = location(?l)
                        + (prod_{?z:zone} [deceleration(?z)]) * move(?l)
                        + Normal(MOVE_MEAN(?l), MOVE_VARIANCE_MULT(?l) * abs[move(?l)]);
    };

    reward = - sqrt[ sum_{?l:dim}[ pow[ GOAL(?l) - location(?l), 2 ] ] ];

    action-preconditions {
        forall_{?l:dim} [move(?l) >= MIN_ACTION_BOUND(?l)];
        forall_{?l:dim} [move(?l) <= MAX_ACTION_BOUND(?l)];
    };
}
